{"id":12217,"className":"com.opengamma.analytics.math.statistics.leastsquare.LeastSquareWithPenaltyResults","methodName":"LeastSquareWithPenaltyResults","signature":"\u003ccom.opengamma.analytics.math.statistics.leastsquare.LeastSquareWithPenaltyResults: void LeastSquareWithPenaltyResults(double,double,com.opengamma.analytics.math.matrix.DoubleMatrix1D,com.opengamma.analytics.math.matrix.DoubleMatrix2D,com.opengamma.analytics.math.matrix.DoubleMatrix2D)\u003e","javadoc":"/** \n * Holder for the results of minimising $\\sum_{i\u003d1}^N (y_i - f_i(\\mathbf{x}))^2 + \\mathbf{x}^T\\mathbf{P}\\mathbf{x}$ WRT $\\mathbf{x}$  (the vector of model parameters). \n * @param chiSqr The value of the first term (the chi-squared)- the sum of squares between the \u0027observed\u0027 values $y_i$ and the model values $f_i(\\mathbf{x})$ \n * @param penalty The value of the second term (the penalty) \n * @param parameters The value of  $\\mathbf{x}$ \n * @param covariance The covariance matrix for  $\\mathbf{x}$ \n * @param inverseJacobian The inverse Jacobian - this is the sensitivities of the model parameters to the \u0027observed\u0027 values \n */\n","tf":{"freq":{"squar":3,"result":2,"mathbf":8,"sensit":1,"jacobian":2,"penalti":3,"holder":1,"model":3,"second":1,"least":1,"matrix":1,"sqr":1,"paramet":3,"sum":2,"invers":2,"observ":2,"term":2,"vector":1,"chi":2,"valu":6,"covari":2,"first":1,"minimis":1},"maxFreq":8,"totalTerms":51},"loc":6}